{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757fe0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Dataset shape: (30000, 25)\n",
      "\n",
      "First few rows:\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Missing values count:\n",
      "ID                            0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default payment next month    0\n",
      "dtype: int64\n",
      "\n",
      "Basic statistics:\n",
      "                 ID       LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
      "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean   15000.500000   167484.322667      1.603733      1.853133      1.551867   \n",
      "std     8660.398374   129747.661567      0.489129      0.790349      0.521970   \n",
      "min        1.000000    10000.000000      1.000000      0.000000      0.000000   \n",
      "25%     7500.750000    50000.000000      1.000000      1.000000      1.000000   \n",
      "50%    15000.500000   140000.000000      2.000000      2.000000      2.000000   \n",
      "75%    22500.250000   240000.000000      2.000000      2.000000      2.000000   \n",
      "max    30000.000000  1000000.000000      2.000000      6.000000      3.000000   \n",
      "\n",
      "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
      "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean      35.485500     -0.016700     -0.133767     -0.166200     -0.220667   \n",
      "std        9.217904      1.123802      1.197186      1.196868      1.169139   \n",
      "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
      "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
      "\n",
      "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
      "count  ...   30000.000000   30000.000000   30000.000000   30000.000000   \n",
      "mean   ...   43262.948967   40311.400967   38871.760400    5663.580500   \n",
      "std    ...   64332.856134   60797.155770   59554.107537   16563.280354   \n",
      "min    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n",
      "25%    ...    2326.750000    1763.000000    1256.000000    1000.000000   \n",
      "50%    ...   19052.000000   18104.500000   17071.000000    2100.000000   \n",
      "75%    ...   54506.000000   50190.500000   49198.250000    5006.000000   \n",
      "max    ...  891586.000000  927171.000000  961664.000000  873552.000000   \n",
      "\n",
      "           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
      "count  3.000000e+04   30000.00000   30000.000000   30000.000000   \n",
      "mean   5.921163e+03    5225.68150    4826.076867    4799.387633   \n",
      "std    2.304087e+04   17606.96147   15666.159744   15278.305679   \n",
      "min    0.000000e+00       0.00000       0.000000       0.000000   \n",
      "25%    8.330000e+02     390.00000     296.000000     252.500000   \n",
      "50%    2.009000e+03    1800.00000    1500.000000    1500.000000   \n",
      "75%    5.000000e+03    4505.00000    4013.250000    4031.500000   \n",
      "max    1.684259e+06  896040.00000  621000.000000  426529.000000   \n",
      "\n",
      "            PAY_AMT6  default payment next month  \n",
      "count   30000.000000                30000.000000  \n",
      "mean     5215.502567                    0.221200  \n",
      "std     17777.465775                    0.415062  \n",
      "min         0.000000                    0.000000  \n",
      "25%       117.750000                    0.000000  \n",
      "50%      1500.000000                    0.000000  \n",
      "75%      4000.000000                    0.000000  \n",
      "max    528666.000000                    1.000000  \n",
      "\n",
      "[8 rows x 25 columns]\n",
      "\n",
      "Starting preprocessing...\n",
      "One-hot encoding categorical variables...\n",
      "Scaling numerical features...\n",
      "Saving preprocessed data...\n",
      "Splitting the data...\n",
      "Saving data splits...\n",
      "\n",
      "Preprocessing Summary:\n",
      "Original data shape: 30000 rows, 24 columns\n",
      "Preprocessed data shape: 30000 rows, 29 columns\n",
      "Training set: 21000 samples\n",
      "Validation set: 4500 samples\n",
      "Test set: 4500 samples\n",
      "\n",
      "Files saved in the 'preprocessed_data' directory:\n",
      "- preprocessed_data.csv: Full preprocessed dataset\n",
      "- train_data.csv: Training set (70% of data)\n",
      "- validation_data.csv: Validation set (15% of data)\n",
      "- test_data.csv: Test set (15% of data)\n",
      "- scaler.pkl: StandardScaler fitted on numerical features\n",
      "- encoder.pkl: OneHotEncoder fitted on categorical features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import os\n",
    "\n",
    "# Create a new directory for preprocessed data\n",
    "os.makedirs('preprocessed_data', exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading the dataset...\")\n",
    "data = pd.read_csv('./data/data.csv')\n",
    "\n",
    "# Display initial information\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values count:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Basic statistical summary\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Preprocessing steps\n",
    "print(\"\\nStarting preprocessing...\")\n",
    "\n",
    "# 1. Handle the ID column (typically not used as a feature)\n",
    "data = data.drop('ID', axis=1)\n",
    "\n",
    "# 2. Identify categorical and numerical columns\n",
    "categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "numerical_cols = ['LIMIT_BAL', 'AGE', \n",
    "                 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
    "                 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "                 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "# 3. Handle missing values\n",
    "# For numerical columns, fill with median\n",
    "for col in numerical_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "# 4. Handle outliers in payment history columns (optional)\n",
    "# Replace values outside the normal range with the mode\n",
    "pay_cols = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for col in pay_cols:\n",
    "    # Normally payment status ranges from -2 to 9\n",
    "    if data[col].max() > 9 or data[col].min() < -2:\n",
    "        mode_value = data[col].mode()[0]\n",
    "        data.loc[(data[col] > 9) | (data[col] < -2), col] = mode_value\n",
    "\n",
    "# 5. Handle education and marriage values\n",
    "# Education should be 1-4, marriage should be 1-3\n",
    "if data['EDUCATION'].max() > 4:\n",
    "    data.loc[data['EDUCATION'] > 4, 'EDUCATION'] = 4\n",
    "if data['MARRIAGE'].max() > 3:\n",
    "    data.loc[data['MARRIAGE'] > 3, 'MARRIAGE'] = 3\n",
    "\n",
    "# 6. One-hot encode categorical variables\n",
    "print(\"One-hot encoding categorical variables...\")\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_cats = encoder.fit_transform(data[categorical_cols])\n",
    "encoded_cols = []\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    categories = encoder.categories_[i][1:]  # Skip the first category (reference)\n",
    "    for cat in categories:\n",
    "        encoded_cols.append(f\"{col}_{cat}\")\n",
    "\n",
    "# Create a DataFrame with encoded categorical variables\n",
    "encoded_df = pd.DataFrame(encoded_cats, columns=encoded_cols)\n",
    "\n",
    "# 7. Scale numerical features\n",
    "print(\"Scaling numerical features...\")\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical = scaler.fit_transform(data[numerical_cols])\n",
    "scaled_df = pd.DataFrame(scaled_numerical, columns=numerical_cols)\n",
    "\n",
    "# 8. Combine all processed features\n",
    "target = data['default payment next month']\n",
    "preprocessed_data = pd.concat([scaled_df, encoded_df], axis=1)\n",
    "preprocessed_data['default_payment'] = target\n",
    "\n",
    "# 9. Save the preprocessed data\n",
    "print(\"Saving preprocessed data...\")\n",
    "preprocessed_data.to_csv('preprocessed_data/preprocessed_data.csv', index=False)\n",
    "\n",
    "# 10. Split the data into training, validation, and testing sets\n",
    "print(\"Splitting the data...\")\n",
    "# First split into training and temp (validation + testing)\n",
    "X = preprocessed_data.drop('default_payment', axis=1)\n",
    "y = preprocessed_data['default_payment']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Then split temp into validation and testing\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# 11. Save the splits\n",
    "print(\"Saving data splits...\")\n",
    "# Training set\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv('preprocessed_data/train_data.csv', index=False)\n",
    "\n",
    "# Validation set\n",
    "val_data = pd.concat([X_val, y_val], axis=1)\n",
    "val_data.to_csv('preprocessed_data/validation_data.csv', index=False)\n",
    "\n",
    "# Test set\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv('preprocessed_data/test_data.csv', index=False)\n",
    "\n",
    "# 12. Save the scaler and encoder for future use\n",
    "import pickle\n",
    "with open('preprocessed_data/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('preprocessed_data/encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# Print summary of the preprocessing\n",
    "print(\"\\nPreprocessing Summary:\")\n",
    "print(f\"Original data shape: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
    "print(f\"Preprocessed data shape: {preprocessed_data.shape[0]} rows, {preprocessed_data.shape[1]} columns\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(\"\\nFiles saved in the 'preprocessed_data' directory:\")\n",
    "print(\"- preprocessed_data.csv: Full preprocessed dataset\")\n",
    "print(\"- train_data.csv: Training set (70% of data)\")\n",
    "print(\"- validation_data.csv: Validation set (15% of data)\")\n",
    "print(\"- test_data.csv: Test set (15% of data)\")\n",
    "print(\"- scaler.pkl: StandardScaler fitted on numerical features\")\n",
    "print(\"- encoder.pkl: OneHotEncoder fitted on categorical features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (3.9.3)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\raksh\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\raksh\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from librosa) (1.15.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\raksh\\.conda\\envs\\myenv\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\raksh\\appdata\\roaming\\python\\python313\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Using cached numba-0.60.0.tar.gz (2.7 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "          exec(compile('''\n",
      "          ~~~~^^^^^^^^^^^^\n",
      "          # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "          ...<31 lines>...\n",
      "          exec(compile(setup_py_code, filename, \"exec\"))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "          ''' % ('C:\\\\Users\\\\raksh\\\\AppData\\\\Local\\\\Temp\\\\pip-install-rzlvt5wi\\\\numba_18e8dcac6d3c4c4e875af3affc9a79fb\\\\setup.py',), \"<pip-setuptools-caller>\", \"exec\"))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\raksh\\AppData\\Local\\Temp\\pip-install-rzlvt5wi\\numba_18e8dcac6d3c4c4e875af3affc9a79fb\\setup.py\", line 51, in <module>\n",
      "          _guard_py_ver()\n",
      "          ~~~~~~~~~~~~~^^\n",
      "        File \"C:\\Users\\raksh\\AppData\\Local\\Temp\\pip-install-rzlvt5wi\\numba_18e8dcac6d3c4c4e875af3affc9a79fb\\setup.py\", line 48, in _guard_py_ver\n",
      "          raise RuntimeError(msg.format(cur_py, min_py, max_py))\n",
      "      RuntimeError: Cannot install on Python version 3.13.0; only versions >=3.9,<3.13 are supported.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib librosa tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from scipy.io import wavfile\n",
    "from random import sample\n",
    "from scipy.signal import spectrogram, resample\n",
    "import random\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_length(file_path):\n",
    "    \"\"\"Get the length of an audio file in seconds.\"\"\"\n",
    "    try:\n",
    "        with wave.open(file_path, 'rb') as wave_file:\n",
    "            frames = wave_file.getnframes()\n",
    "            rate = wave_file.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            return duration\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def create_dataset_df(root_dir):\n",
    "    \"\"\"Create a DataFrame with file paths and their classes.\"\"\"\n",
    "    data = []\n",
    "    for class_name in os.listdir(root_dir):\n",
    "        class_path = os.path.join(root_dir, class_name)\n",
    "        if os.path.isdir(class_path) and not class_name.startswith('.'):\n",
    "            for file_name in os.listdir(class_path):\n",
    "                if file_name.endswith('.wav'):\n",
    "                    file_path = os.path.join(class_path, file_name)\n",
    "                    audio_length = get_audio_length(file_path)\n",
    "                    if audio_length is not None:\n",
    "                        data.append({\n",
    "                            'file_path': file_path,\n",
    "                            'class': class_name,\n",
    "                            'length': audio_length\n",
    "                        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def safe_split(df, split_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Safely split DataFrame even with very few samples.\n",
    "    Returns train and test splits while ensuring at least one sample in each split.\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    if len(df) == 1:\n",
    "        # If only one sample, put it in train set\n",
    "        return df, pd.DataFrame()\n",
    "    \n",
    "    if len(df) == 2:\n",
    "        # If two samples, split them between train and test\n",
    "        return df.iloc[[0]], df.iloc[[1]]\n",
    "    \n",
    "    # For more than 2 samples, use train_test_split\n",
    "    try:\n",
    "        train_size = max(1, int(len(df) * split_ratio))\n",
    "        train_df = df.sample(n=train_size, random_state=42)\n",
    "        test_df = df.drop(train_df.index)\n",
    "        return train_df, test_df\n",
    "    except:\n",
    "        # Fallback for any unexpected cases\n",
    "        mid = int(len(df) * split_ratio)\n",
    "        return df.iloc[:mid], df.iloc[mid:]\n",
    "\n",
    "def create_split_directories(base_path):\n",
    "    \"\"\"Create directories for train, validation, and test sets.\"\"\"\n",
    "    splits = ['train', 'validation', 'test']\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            os.makedirs(split_path)\n",
    "\n",
    "def copy_files_to_split(df, split_name, base_path):\n",
    "    \"\"\"Copy files to their respective split directories.\"\"\"\n",
    "    if len(df) == 0:\n",
    "        print(f\"No files to copy for {split_name} split\")\n",
    "        return\n",
    "        \n",
    "    for _, row in tqdm(df.iterrows(), desc=f\"Copying {split_name} files\"):\n",
    "        class_name = row['class']\n",
    "        class_dir = os.path.join(base_path, split_name, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "        shutil.copy2(row['file_path'], \n",
    "                    os.path.join(class_dir, os.path.basename(row['file_path'])))\n",
    "\n",
    "def plot_average_lengths(df):\n",
    "    \"\"\"Plot average audio length per class.\"\"\"\n",
    "    avg_lengths = df.groupby('class')['length'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    avg_lengths.plot(kind='bar')\n",
    "    plt.title('Average Audio Length per Class')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Average Length (seconds)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('average_audio_lengths.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return avg_lengths\n",
    "\n",
    "def split_dataset(df):\n",
    "    \"\"\"Split dataset into train, validation, and test sets.\"\"\"\n",
    "    # Split by class to ensure at least one sample per class in training\n",
    "    train_dfs = []\n",
    "    val_dfs = []\n",
    "    test_dfs = []\n",
    "    \n",
    "    for class_name in df['class'].unique():\n",
    "        class_df = df[df['class'] == class_name]\n",
    "        \n",
    "        # First split: 80% for train, 20% for rest\n",
    "        train_df, rest_df = safe_split(class_df, split_ratio=0.8)\n",
    "        \n",
    "        # Second split: split remaining data 50-50 for validation and test\n",
    "        val_df, test_df = safe_split(rest_df, split_ratio=0.5)\n",
    "        \n",
    "        train_dfs.append(train_df)\n",
    "        val_dfs.append(val_df)\n",
    "        test_dfs.append(test_df)\n",
    "    \n",
    "    return (pd.concat(train_dfs, ignore_index=True),\n",
    "            pd.concat(val_dfs, ignore_index=True),\n",
    "            pd.concat(test_dfs, ignore_index=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    \"\"\"Load audio file and return sample rate and data.\"\"\"\n",
    "    sample_rate, data = wavfile.read(file_path)\n",
    "    # Convert to mono if stereo\n",
    "    if len(data.shape) > 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    # Normalize the data\n",
    "    data = data.astype(float)\n",
    "    data /= np.max(np.abs(data))\n",
    "    return sample_rate, data\n",
    "\n",
    "def compute_zcr(audio_data, frame_length=2048, hop_length=512):\n",
    "    \"\"\"Compute Zero Crossing Rate for frames of audio data.\"\"\"\n",
    "    zcr = []\n",
    "    # Process frame by frame\n",
    "    for i in range(0, len(audio_data) - frame_length, hop_length):\n",
    "        frame = audio_data[i:i + frame_length]\n",
    "        # Count zero crossings\n",
    "        zero_crossings = np.sum(np.abs(np.diff(np.signbit(frame).astype(int))))\n",
    "        zcr.append(zero_crossings / frame_length)\n",
    "    return np.mean(zcr)\n",
    "\n",
    "def compute_autocorrelation(audio_data, max_lag=100):\n",
    "    \"\"\"Compute autocorrelation of audio data.\"\"\"\n",
    "    # Normalize the signal\n",
    "    audio_data = audio_data - np.mean(audio_data)\n",
    "    # Compute autocorrelation\n",
    "    correlation = np.correlate(audio_data, audio_data, mode='full')\n",
    "    # Take only the positive lags (center to end)\n",
    "    correlation = correlation[len(correlation)//2:len(correlation)//2 + max_lag]\n",
    "    # Normalize\n",
    "    correlation = correlation / correlation[0]\n",
    "    return correlation\n",
    "\n",
    "def plot_features(audio_data, sample_rate, zcr, autocorr, filename):\n",
    "    \"\"\"Plot waveform, ZCR, and autocorrelation.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    fig.suptitle(f'Audio Analysis for {os.path.basename(filename)}')\n",
    "    \n",
    "    # Plot waveform\n",
    "    time = np.arange(len(audio_data)) / sample_rate\n",
    "    axes[0].plot(time, audio_data)\n",
    "    axes[0].set_title('Waveform')\n",
    "    axes[0].set_xlabel('Time (s)')\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Plot ZCR\n",
    "    axes[1].axhline(y=zcr, color='r', linestyle='-')\n",
    "    axes[1].set_title(f'Zero Crossing Rate (Mean: {zcr:.4f})')\n",
    "    axes[1].set_ylabel('ZCR')\n",
    "    \n",
    "    # Plot autocorrelation\n",
    "    lags = np.arange(len(autocorr))\n",
    "    axes[2].plot(lags, autocorr)\n",
    "    axes[2].set_title('Autocorrelation')\n",
    "    axes[2].set_xlabel('Lag')\n",
    "    axes[2].set_ylabel('Correlation')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./zcrAC/analysis_{os.path.basename(filename)}.png')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_random_files(train_dir, n_files=5):\n",
    "    \"\"\"Analyze n random audio files from the training set.\"\"\"\n",
    "    # Get all audio files from training directory\n",
    "    audio_files = []\n",
    "    for root, _, files in os.walk(train_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Randomly select n files\n",
    "    if len(audio_files) < n_files:\n",
    "        print(f\"Warning: Only {len(audio_files)} files available\")\n",
    "        selected_files = audio_files\n",
    "    else:\n",
    "        selected_files = sample(audio_files, n_files)\n",
    "    \n",
    "    # Analyze each selected file\n",
    "    results = []\n",
    "    for file_path in selected_files:\n",
    "        print(f\"\\nAnalyzing {os.path.basename(file_path)}...\")\n",
    "        \n",
    "        # Load audio\n",
    "        sample_rate, audio_data = load_audio(file_path)\n",
    "        \n",
    "        # Compute features\n",
    "        zcr = compute_zcr(audio_data)\n",
    "        autocorr = compute_autocorrelation(audio_data)\n",
    "        \n",
    "        # Plot features\n",
    "        plot_features(audio_data, sample_rate, zcr, autocorr, file_path)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'file': os.path.basename(file_path),\n",
    "            'class': os.path.basename(os.path.dirname(file_path)),\n",
    "            'zcr': zcr,\n",
    "            'autocorr_peak': np.max(autocorr[1:]),  # Exclude lag 0\n",
    "            'sample_rate': sample_rate,\n",
    "            'duration': len(audio_data) / sample_rate\n",
    "        })\n",
    "    \n",
    "    # Create and display results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nAnalysis Results:\")\n",
    "    print(results_df)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_path):\n",
    "    \"\"\"Load audio file and return sample rate and data.\"\"\"\n",
    "    sample_rate, data = wavfile.read(file_path)\n",
    "    # Convert to mono if stereo\n",
    "    if len(data.shape) > 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    # Normalize the data\n",
    "    data = data.astype(float)\n",
    "    data /= np.max(np.abs(data))\n",
    "    return sample_rate, data\n",
    "\n",
    "def create_spectrogram(audio_data, sample_rate, title):\n",
    "    \"\"\"Generate and plot spectrogram.\"\"\"\n",
    "    # Compute spectrogram\n",
    "    frequencies, times, Sxx = spectrogram(audio_data, fs=sample_rate, \n",
    "                                        nperseg=256, noverlap=128)\n",
    "    \n",
    "    # Convert to dB scale\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-10)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pcolormesh(times, frequencies, Sxx_db, shading='gouraud')\n",
    "    plt.title(f'Spectrogram - {title}')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.colorbar(label='Intensity [dB]')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'./spectrogram/spectrogram_{title.replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "def get_class_directories(train_dir):\n",
    "    \"\"\"Get all class directories from training set.\"\"\"\n",
    "    return [d for d in os.listdir(train_dir) \n",
    "            if os.path.isdir(os.path.join(train_dir, d))]\n",
    "\n",
    "def get_random_audio_file(class_dir):\n",
    "    \"\"\"Get a random audio file from the given class directory.\"\"\"\n",
    "    audio_files = [f for f in os.listdir(class_dir) \n",
    "                   if f.endswith('.wav')]\n",
    "    if audio_files:\n",
    "        return os.path.join(class_dir, random.choice(audio_files))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load an audio file\n",
    "def load_audio(file_path):\n",
    "    sample_rate, audio_data = wav.read(file_path)\n",
    "    return sample_rate, audio_data\n",
    "\n",
    "# Function to save an audio file\n",
    "def save_audio(file_path, sample_rate, audio_data):\n",
    "    wav.write(file_path, sample_rate, audio_data)\n",
    "\n",
    "# Function to change the pitch of audio\n",
    "def change_pitch(audio_data, sample_rate, pitch_factor):\n",
    "    indices = np.round(np.arange(0, len(audio_data), pitch_factor))\n",
    "    indices = indices[indices < len(audio_data)].astype(int)\n",
    "    return audio_data[indices]\n",
    "\n",
    "# Function to add background noise\n",
    "def add_background_noise(audio_data, noise_factor=0.005):\n",
    "    noise = np.random.normal(0, 1, len(audio_data))\n",
    "    augmented_audio = audio_data + noise_factor * noise * np.max(audio_data)\n",
    "    return augmented_audio.astype(audio_data.dtype)\n",
    "\n",
    "# Function to time-stretch audio\n",
    "def time_stretch(audio_data, stretch_factor):\n",
    "    num_samples = int(len(audio_data) * stretch_factor)\n",
    "    stretched_audio = resample(audio_data, num_samples)\n",
    "    return stretched_audio.astype(audio_data.dtype)\n",
    "\n",
    "# Function to apply augmentations sequentially and save them\n",
    "def apply_augmentations(train_dir, output_dir):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # List all class directories\n",
    "    class_dirs = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
    "    \n",
    "    # Randomly select 5 files from the dataset\n",
    "    selected_files = []\n",
    "    for class_dir in class_dirs:\n",
    "        class_path = os.path.join(train_dir, class_dir)\n",
    "        audio_files = [f for f in os.listdir(class_path) if f.endswith('.wav')]\n",
    "        if audio_files:\n",
    "            selected_files.append(os.path.join(class_path, random.choice(audio_files)))\n",
    "    \n",
    "    # Limit to 5 files if more than 5 are selected\n",
    "    selected_files = random.sample(selected_files, min(5, len(selected_files)))\n",
    "\n",
    "    print(\"Selected files for augmentation:\")\n",
    "    for file in selected_files:\n",
    "        print(file)\n",
    "\n",
    "    for file_path in selected_files:\n",
    "        sample_rate, audio_data = load_audio(file_path)\n",
    "\n",
    "        # Get the class name and file name\n",
    "        class_name = os.path.basename(os.path.dirname(file_path))\n",
    "        file_name = os.path.basename(file_path).replace('.wav', '')\n",
    "\n",
    "        # Create class-specific output directory\n",
    "        class_output_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "        # Apply and save pitch change\n",
    "        pitch_changed = change_pitch(audio_data, sample_rate, pitch_factor=1.2)\n",
    "        pitch_file_path = os.path.join(class_output_dir, f\"{file_name}_pitch.wav\")\n",
    "        save_audio(pitch_file_path, sample_rate, pitch_changed)\n",
    "        print(f\"Pitch-changed audio saved: {pitch_file_path}\")\n",
    "\n",
    "        # Apply and save background noise\n",
    "        noisy_audio = add_background_noise(audio_data)\n",
    "        noise_file_path = os.path.join(class_output_dir, f\"{file_name}_noise.wav\")\n",
    "        save_audio(noise_file_path, sample_rate, noisy_audio)\n",
    "        print(f\"Noisy audio saved: {noise_file_path}\")\n",
    "\n",
    "        # Apply and save time-stretch\n",
    "        stretched_audio = time_stretch(audio_data, stretch_factor=1.5)\n",
    "        stretch_file_path = os.path.join(class_output_dir, f\"{file_name}_stretch.wav\")\n",
    "        save_audio(stretch_file_path, sample_rate, stretched_audio)\n",
    "        print(f\"Time-stretched audio saved: {stretch_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing 8494fba8_nohash_0.wav...\n",
      "\n",
      "Analyzing 8910e5ef_nohash_1.wav...\n",
      "\n",
      "Analyzing b4ea0d9a_nohash_6.wav...\n",
      "\n",
      "Analyzing be7a5b2d_nohash_4.wav...\n",
      "\n",
      "Analyzing b0f5b16d_nohash_3.wav...\n",
      "\n",
      "Analysis Results:\n",
      "                    file    class       zcr  autocorr_peak  sample_rate  \\\n",
      "0  8494fba8_nohash_0.wav      yes  0.209880       0.674165        16000   \n",
      "1  8910e5ef_nohash_1.wav    eight  0.075422       0.941178        16000   \n",
      "2  b4ea0d9a_nohash_6.wav      one  0.141950       0.948823        16000   \n",
      "3  be7a5b2d_nohash_4.wav     nine  0.053031       0.980683        16000   \n",
      "4  b0f5b16d_nohash_3.wav  forward  0.231410       0.959451        16000   \n",
      "\n",
      "   duration  \n",
      "0     0.896  \n",
      "1     1.000  \n",
      "2     1.000  \n",
      "3     1.000  \n",
      "4     1.000  \n",
      "\n",
      "Generating spectrograms for the following classes:\n",
      "Processing class: nine\n",
      "Processing class: visual\n",
      "Processing class: seven\n",
      "Processing class: one\n",
      "Processing class: two\n",
      "Selected files for augmentation:\n",
      "./seg/train\\learn\\51f7a034_nohash_4.wav\n",
      "./seg/train\\right\\ee6163d5_nohash_1.wav\n",
      "./seg/train\\one\\0d90d8e1_nohash_2.wav\n",
      "./seg/train\\six\\686d030b_nohash_2.wav\n",
      "./seg/train\\forward\\608473c9_nohash_0.wav\n",
      "Pitch-changed audio saved: ./augmented\\learn\\51f7a034_nohash_4_pitch.wav\n",
      "Noisy audio saved: ./augmented\\learn\\51f7a034_nohash_4_noise.wav\n",
      "Time-stretched audio saved: ./augmented\\learn\\51f7a034_nohash_4_stretch.wav\n",
      "Pitch-changed audio saved: ./augmented\\right\\ee6163d5_nohash_1_pitch.wav\n",
      "Noisy audio saved: ./augmented\\right\\ee6163d5_nohash_1_noise.wav\n",
      "Time-stretched audio saved: ./augmented\\right\\ee6163d5_nohash_1_stretch.wav\n",
      "Pitch-changed audio saved: ./augmented\\one\\0d90d8e1_nohash_2_pitch.wav\n",
      "Noisy audio saved: ./augmented\\one\\0d90d8e1_nohash_2_noise.wav\n",
      "Time-stretched audio saved: ./augmented\\one\\0d90d8e1_nohash_2_stretch.wav\n",
      "Pitch-changed audio saved: ./augmented\\six\\686d030b_nohash_2_pitch.wav\n",
      "Noisy audio saved: ./augmented\\six\\686d030b_nohash_2_noise.wav\n",
      "Time-stretched audio saved: ./augmented\\six\\686d030b_nohash_2_stretch.wav\n",
      "Pitch-changed audio saved: ./augmented\\forward\\608473c9_nohash_0_pitch.wav\n",
      "Noisy audio saved: ./augmented\\forward\\608473c9_nohash_0_noise.wav\n",
      "Time-stretched audio saved: ./augmented\\forward\\608473c9_nohash_0_stretch.wav\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # # Define paths\n",
    "    # dataset_path = './archive'  # Current directory\n",
    "    # output_base_path = './seg'\n",
    "    \n",
    "    # # Create DataFrame of the dataset\n",
    "    # print(\"Creating dataset DataFrame...\")\n",
    "    # df = create_dataset_df(dataset_path)\n",
    "    \n",
    "    # if len(df) == 0:\n",
    "    #     print(\"No .wav files found in the current directory structure!\")\n",
    "    #     return\n",
    "    \n",
    "    # # Calculate and plot average lengths\n",
    "    # print(\"Calculating average lengths per class...\")\n",
    "    # avg_lengths = plot_average_lengths(df)\n",
    "    # print(\"\\nAverage audio lengths per class:\")\n",
    "    # print(avg_lengths)\n",
    "    \n",
    "    # # Print initial class distribution\n",
    "    # print(\"\\nInitial class distribution:\")\n",
    "    # print(df['class'].value_counts())\n",
    "    \n",
    "    # # Split the dataset\n",
    "    # print(\"\\nSplitting dataset...\")\n",
    "    # train_df, val_df, test_df = split_dataset(df)\n",
    "    \n",
    "    # # Create directories for splits\n",
    "    # create_split_directories(output_base_path)\n",
    "    \n",
    "    # # Copy files to their respective directories\n",
    "    # print(\"\\nCopying files to split directories...\")\n",
    "    # copy_files_to_split(train_df, 'train', output_base_path)\n",
    "    # copy_files_to_split(val_df, 'validation', output_base_path)\n",
    "    # copy_files_to_split(test_df, 'test', output_base_path)\n",
    "    \n",
    "    # # Print split statistics\n",
    "    # print(\"\\nDataset split statistics:\")\n",
    "    # print(f\"Total samples: {len(df)}\")\n",
    "    # print(f\"Training samples: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    # print(f\"Validation samples: {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "    # print(f\"Testing samples: {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # # Print class distribution in each split\n",
    "    # splits = {'Training': train_df, 'Validation': val_df, 'Testing': test_df}\n",
    "    # for split_name, split_df in splits.items():\n",
    "    #     print(f\"\\n{split_name} class distribution:\")\n",
    "    #     print(split_df['class'].value_counts())\n",
    "        \n",
    "    train_dir = \"./seg/train\"\n",
    "    \n",
    "    \"\"\"PART C\"\"\"\n",
    "    \n",
    "    results_df = analyze_random_files(train_dir)\n",
    "    results_df.to_csv('./zcrAC/audio_analysis_results.csv', index=False)\n",
    "    \n",
    "    \"\"\"PART D\"\"\"\n",
    "    \n",
    "    class_dirs = get_class_directories(train_dir)\n",
    "    if len(class_dirs) < 5:\n",
    "        print(f\"Not enough classes found. Only {len(class_dirs)} classes available.\")\n",
    "        selected_classes = class_dirs\n",
    "    else:\n",
    "        selected_classes = random.sample(class_dirs, 5)\n",
    "    print(\"\\nGenerating spectrograms for the following classes:\")\n",
    "    for class_name in selected_classes:\n",
    "        class_dir = os.path.join(train_dir, class_name)\n",
    "        audio_file = get_random_audio_file(class_dir)\n",
    "        if audio_file:\n",
    "            print(f\"Processing class: {class_name}\")\n",
    "            sample_rate, audio_data = load_audio(audio_file)\n",
    "            create_spectrogram(audio_data, sample_rate, \n",
    "                             f\"Class {class_name}\")\n",
    "        else:\n",
    "            print(f\"No audio files found in class: {class_name}\")\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"Part E\"\"\"       \n",
    "\n",
    "    output_dir = \"./augmented\"\n",
    "    apply_augmentations(train_dir, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
